{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install datasets\n",
    "# ! pip install -U accelerate\n",
    "# ! pip install -U transformers\n",
    "\n",
    "from utils import (load_difficulty_classifier_model, load_tag_classifier_model,\n",
    "                   predict_difficulty, predict_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_INPUT = \"\"\"H. 378QAQ and Core\n",
    "time limit per test2 seconds\n",
    "memory limit per test256 megabytes\n",
    "inputstandard input\n",
    "outputstandard output\n",
    "378QAQ has a string s\n",
    " of length n\n",
    ". Define the core of a string as the substring†\n",
    " with maximum lexicographic‡\n",
    " order.\n",
    "\n",
    "For example, the core of \"bazoka\n",
    "\" is \"zoka\n",
    "\", and the core of \"aaa\n",
    "\" is \"aaa\n",
    "\".\n",
    "\n",
    "378QAQ wants to rearrange the string s\n",
    " so that the core is lexicographically minimum. Find the lexicographically minimum possible core over all rearrangements of s\n",
    ".\n",
    "\n",
    "†\n",
    " A substring of string s\n",
    " is a continuous segment of letters from s\n",
    ". For example, \"defor\n",
    "\", \"code\n",
    "\" and \"o\n",
    "\" are all substrings of \"codeforces\n",
    "\" while \"codes\n",
    "\" and \"aaa\n",
    "\" are not.\n",
    "\n",
    "‡\n",
    " A string p\n",
    " is lexicographically smaller than a string q\n",
    " if and only if one of the following holds:\n",
    "\n",
    "p\n",
    " is a prefix of q\n",
    ", but p≠q\n",
    "; or\n",
    "in the first position where p\n",
    " and q\n",
    " differ, the string p\n",
    " has a smaller element than the corresponding element in q\n",
    " (when compared by their ASCII code).\n",
    "For example, \"code\n",
    "\" and \"coda\n",
    "\" are both lexicographically smaller than \"codeforces\n",
    "\" while \"codeforceston\n",
    "\" and \"z\n",
    "\" are not.\n",
    "\n",
    "Input\n",
    "Each test contains multiple test cases. The first line contains the number of test cases t\n",
    " (1≤t≤105\n",
    "). The description of the test cases follows.\n",
    "\n",
    "The first line of each test case contains a single integer n\n",
    " (1≤n≤106\n",
    ") — the length of string s\n",
    ".\n",
    "\n",
    "The next line of each test case contains the string s\n",
    " of length n\n",
    ". The string s\n",
    " consists of lowercase English letters.\n",
    "\n",
    "It is guaranteed that the sum of n\n",
    " over all test cases does not exceed 106\n",
    ".\n",
    "\n",
    "Output\n",
    "For each test case, output the lexicographically minimum possible core over all rearrangements of s.\"\"\"\n",
    "\n",
    "EXPECTED_DIFFICULTY = None\n",
    "EXPECTED_TAGS = ['greedy', 'strings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pretrained tranformer model\n",
    "difficulty_model_name = 'google_bigbird-roberta-base_difficulty_classifier'\n",
    "tag_model_name = 'google_bigbird-roberta-base_tag_classifier'\n",
    "\n",
    "difficulty_model, difficulty_tokenizer, difficulty_config = load_difficulty_classifier_model(difficulty_model_name, use_pretrained_transformer=True)\n",
    "tag_model, tag_tokenizer, tag_config = load_tag_classifier_model(tag_model_name, use_pretrained_transformer=True)\n",
    "\n",
    "difficulty_range = predict_difficulty(TEXT_INPUT, difficulty_model, difficulty_tokenizer, difficulty_config)\n",
    "problem_tags = predict_tags(TEXT_INPUT, tag_model, tag_tokenizer, tag_config)\n",
    "\n",
    "print(difficulty_range)\n",
    "print(problem_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2id = tag_config[\"tag2id\"]\n",
    "tag2id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e2_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
